{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Data Engineer of the â€œðŸŒ±Sqaure Meter GardeningðŸŒ±â€ project, you are responsible for providing the marketing team a **weekly KPI report**. The datapipeline includes (1) extracting data from database and (2) processing data to get required KPIs. To improve work efficiency, reduce erros that may occur with manual work, and ensure the consistency and reliability of the reporting work, you decide to automate this repetitive task using Apache Airflow. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "from airflow import DAG\n",
    "from airflow.operators.postgres_operator import PostgresOperator\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'DataEngineeringTea',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime.now(),\n",
    "    'email': ['data_engineer@YourSquaremetergardening.com'],\n",
    "    'email_on_failure': TRUE,\n",
    "    'email_on_retry': TRUE,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'weekly_kpi_report',\n",
    "    default_args=default_args,\n",
    "    description='Data Pipeline for Sqaure Meter Gardening project weekly KPI report',\n",
    "    schedule_interval='59 23 * * 0',  # Run at 12 PM every Sunday\n",
    "    catchup=False,\n",
    ")\n",
    "\n",
    "def fetch_data():\n",
    "    # Connect to PostgreSQL database and fetch data\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"gardening_commerce_db\",\n",
    "        user=\"dataengineerteam\",\n",
    "        password=\"your_email_password\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(open('fetch_data.sql', 'r').read())\n",
    "    records = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description]\n",
    "    df = pd.DataFrame(records, columns=columns)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "def calculate_kpis(df):\n",
    "    # Calculate KPIs: Volume of Transactions, Average Order Value, Average Basket Size\n",
    "    volume_of_transactions = len(df)\n",
    "    average_order_value = df['TotalAmount'].mean()\n",
    "    average_basket_size = df.groupby('OrderID')['ProductId'].count().mean()\n",
    "    # Generate the KPI report\n",
    "    report = f\"Weekly KPI Report:\\nVolume of Transactions: {volume_of_transactions}\\nAverage Order Value: {average_order_value}\\nBasket Size: {average_basket_size}\"\n",
    "    print(report)\n",
    "    return volume_of_transactions, average_order_value, average_basket_size\n",
    "\n",
    "    \n",
    "# Task to extract data from source systems\n",
    "fetch_data_task = PythonOperator(\n",
    "        task_id='fetch_data',\n",
    "        python_callable=fetch_data,\n",
    "        dag=dag,\n",
    "    )\n",
    "\n",
    "calculate_kpis_task = PythonOperator(\n",
    "        task_id='calculate_kpis',\n",
    "        python_callable=calculate_kpis,\n",
    "        op_args=[fetch_data_task.output],\n",
    "        dag=dag,\n",
    "    )\n",
    "\n",
    "# Define task dependencies\n",
    "fetch_data_task >> calculate_kpis_task\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You created a DAG named weekly_kpi_report and defined two tasks in this DAG: fetch_data_task >> calculate_kpis_task. The DAG is configured to run every Sunday at 23:59PM. [Astronomer - DAG scheduling and timetables in Airflow](https://docs.astronomer.io/learn/scheduling-in-airflow)\n",
    "\n",
    "The first task, fetch_data_task, aims to fetch data from the database. Here we join Order and Order_Detail table and fetch all order data within the last 7 days.\n",
    "\n",
    "The second task, calculate_kpis_task, calculates the three KPIs that the marketing department is currently most concerned about.\n",
    "- Volume of Transactions: This KPI quantifies the total volume of transactions conducted through the platform.\n",
    "- Average Order Value: The average amount of money spent by customers in a single order. AOV = Total Revenue / Number of Orders\n",
    "- Basket Size: The average number of items purchased per order.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
